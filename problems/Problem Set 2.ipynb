{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Problem Set 2 - Arctic ice maps"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Total points:** 30\n",
      "\n",
      "**Due:** Thursday 25th 18:00\n",
      "\n",
      "**Format:** IPython Notebook"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The purpose of this problem set is to become familiar with working with image data, plotting it, and combining it in various ways for analysis.\n",
      "\n",
      "The data used in this problem set was collected by the AMSR-E instrument [Aqua](http://en.wikipedia.org/wiki/Aqua_%28satellite%29) satellite. The data consists of maps of the concentration of ice in the Arctic collected between 2006 and 2011. I have downloaded and extracted the maps from [here](http://www.iup.uni-bremen.de/seaice/amsr/) and have put them in a format that you can more easily used (if you are interested in using the raw data directly, let me know and I can show you).\n",
      "\n",
      "The data you should is in the [data/ice_data.tgz](data/ice_data.tgz) file and can also be accessed in ``/local/py4sci/ice_data`` if you are using the CIP computers (no need to copy over that directory, just read the files from there). This is actually a subset of the data, with only two ice maps every month, but let me know if you are interested in getting the full dataset.\n",
      "\n",
      "The data is in 'Numpy' format, which means that you can read it as a Numpy array using:\n",
      "\n",
      "    >>> import numpy as np\n",
      "    >>> data = np.load('ice_data/20080415.npy')\n",
      "\n",
      "which will give you a 2-d array. Just for information, this was created with:\n",
      "\n",
      "    >>> np.save('ice_data/20080415.npy', data)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 1 - examining a single map (6 points)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Start off by reading in one of the maps as shown above, and plot it with Matplotlib**. Note that to get the correct orientation, you will need to call the ``imshow`` command with the ``origin='lower'`` option, which ensures that the (0,0) pixels is on the bottom left, not the top left. You can try and use different colormaps if you like (set by the ``cmap`` option) - see [here](http://www.scipy.org/Cookbook/Matplotlib/Show_colormaps) for information on the available colormaps. You can specify a colormap to use with e.g. ``cmap=plt.cm.jet`` (i.e. ``cmap=plt.cm.`` followed by the name of the colormap). Note that you can make figures larger by specifying e.g.\n",
      "\n",
      "    >>> plt.figure(figsize=(8,8))\n",
      "\n",
      "where the size is given in inches. Try and find a way to plot a colorbar on the side, to show what color corresponds to what value. Remember that you can always look at the examples in the [Matplotlib Gallery](http://matplotlib.org/gallery.html) to find examples. You can also try and remove the tick labels (``100``, ``200``, etc.) since they are not useful - but don't worry if you can't figure out how."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 2 - reading in multiple maps (10 points)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We now want to make a plot of the ice concentration over time. Reading in a single map is easy, but since we have 137 maps, we do not want to read them all in individually by hand. **Write a loop over all the available files, and inside the loop, read in the data to a variable (e.g. ``data``), and also extract the year, month, and day as integer values (e.g. ``year``, ``month``, and ``day``)**. Then, also inside the loop, **compute a variable ``time``** which is essentially the fractional time in years (so 1st July 2012 is 2012.5). You can assume for simplicity that each month has 30 days - this will not affect the results later. Finally, also **compute for each file the total number of pixels that have a value above 50%**. After the loop, **make a plot of the number of pixels with a concentration above 50% against time**.\n",
      "\n",
      "You will likely notice that the ticks are in a strange format, where they are given in years since 2006, but you can change this with the following code:\n",
      "\n",
      "    >>> from matplotlib.ticker import ScalarFormatter\n",
      "    >>> plt.gca().xaxis.set_major_formatter(ScalarFormatter(useOffset=False))\n",
      "\n",
      "**Describe what you see in the plot**.\n",
      "\n",
      "We now want something a little more quantitative than just the number of pixels, so we will try and compute the effective area of ice coverage, which we will define as the area that the icy region would be if we took all the ice and put it in one place. However, we first need to know the area of the pixels in the image, and since we are looking at a projection of a spherical surface, each pixel will be a different area. The areas (in km^2) are contained inside the file named ``ice_data_area.npy`` (if you are using the CIP pool, this is ``/local/py4sci/ice_data_area.npy``). **Read in this data and make a plot (with colorbar) to see how the pixel area is changing over the image.**\n",
      "\n",
      "Now, **loop over the files again as before, but this time, compute for each pixel the effective area of ice** (given by the pixel area times the ice concentration) and then find the total effective area of ice over the image (remember that the values of the concentration are given as a percentage between 0 and 100!). In the same loop, compute the total area where the concentration of ice is 99% or above. **Make a new plot of the effective area of the ice** and the area of >99% ice concentration against time (use different colors for the two datasets).\n",
      "\n",
      "**IMPORTANT** - some of the pixels in the maps are set to ``NaN`` - meaning *Not a Number*. If you multiply a ``NaN`` value by another value, you get ``NaN``, and if there are any ``NaN`` values in your summation, the total result will be ``NaN``. One way to get around this is to use ``np.nansum`` instead of ``np.sum`` in order to find the sum. You can also use ``np.isnan`` to tell you where values are ``NaN``. For example, ``array[~np.isnan(array)]`` will return all the values that are *not* ``NaN`` (because ``~`` means 'not').\n",
      "\n",
      "**Describe what you see - how does the minimum change over time for each of the curves?**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 3 - visualizing changes over time (10 points)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Find the date at which the area of the region where the ice concentration is above 99% is the smallest**. What is the value of the minimum area?\n",
      "\n",
      "Next, **read in the map for this minimum, and the map for the same day and month but from 2006**. **Make a side-by-side plot showing the 2006 and the 2011 data**.\n",
      "\n",
      "**Compute the difference between the two maps** so that a loss in ice over time will correspond to a negative value, and a gain in ice will correspond to a positive value. **Make a plot** of the difference, and use the ``RdBu`` colormap to highlight the changes (include a colorbar)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 4 - yearly averages (4 points)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Compute average ice concentration maps for 2006 and 2011, and plot them side by side.**"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Epilogue"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The data that we have here only cover five years, so we cannot reliably extract information about long term trends. However, it is worth noting that the minimum ice coverage you found here was a record minimum - never before (in recorded history) had the size of the ice shelf been so small. This is part of a long term trend due to global warming. In 2012, the record was again beaten, and most scientists believe that by ~2050, the Arctic will be completely ice-free for at least part of the summer."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}